{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: 李享 Louis\n",
    "\n",
    "Student ID: 111062699\n",
    "\n",
    "GitHub ID:\n",
    "\n",
    "Kaggle name:\n",
    "\n",
    "Kaggle private scoreboard snapshot:\n",
    "\n",
    "[Snapshot](img/pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home** exercises in the [DM2022-Lab2-master Repo](https://github.com/keziatamus/DM2022-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm2022-isa5810-lab2-homework) regarding Emotion Recognition on Twitter by this link https://www.kaggle.com/t/2b0d14a829f340bc88d2660dc602d4bd. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (60-x)/6 + 20 points, where x is your ranking in the leaderboard (ie. If you rank 3rd your score will be (60-3)/6 + 20 = 29.5% out of 30%)   \n",
    "    Submit your last submission __BEFORE the deadline (Nov. 22th 11:59 pm, Tuesday)_. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developping the model for the competition (You can use code and comment it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook** and **add minimal comments where needed**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 25th 11:59 pm, Friday)__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Begin Assignment Here\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path = 'dm2022-isa5810-lab2-homework/'\n",
    "ori_tweets_data = pd.read_json(path + 'tweets_DM.json', lines=True)\n",
    "ori_tweets_label = pd.read_csv(path + 'emotion.csv')\n",
    "tweet_train_predict_split = pd.read_csv(path + 'data_identification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_index' and '_type' are all the same in this dataset, so drop it.\n",
    "\n",
    "tweets_data = ori_tweets_data.drop(columns=['_index', '_type'])\n",
    "tweets_label = ori_tweets_label.drop(columns=['tweet_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "j = json.loads(json.dumps(tweets_data['_source'].values[0], indent=4))['tweet']\n",
    "# all informations are in `tweet` key, so I need to extract all informations in `tweet`\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "score, hashtags, tweet_id, text = [], [], [], []\n",
    "score = pd.DataFrame({ 'score': tweets_data['_score'].values.tolist() })\n",
    "\n",
    "for idx, d in enumerate(tweets_data['_source'].values):\n",
    "    if len(d['tweet']['hashtags']) == 0:\n",
    "        hashtags.append(None)\n",
    "    else:\n",
    "        hashtags.append(d['tweet']['hashtags'])\n",
    "    tweet_id.append(d['tweet']['tweet_id'])\n",
    "    text.append(re.sub(r'[^\\w\\s]', '', d['tweet']['text']))\n",
    "\n",
    "hashtags = pd.DataFrame({'hashtags': hashtags})\n",
    "tweet_id = pd.DataFrame(tweet_id, columns=['tweet_id'])\n",
    "text = pd.DataFrame(text, columns=['text'])\n",
    "\n",
    "tweets_data = pd.concat([tweets_data, hashtags, tweet_id, text], axis=1)\n",
    "tweets_data = tweets_data.drop(columns=['_source'])\n",
    "# tweets_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_data.to_csv(path + 'split_tweet_data.csv', index=False)\n",
    "split_data = pd.read_csv(path + 'split_tweet_data.csv', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# tfidf = TfidfVectorizer()\n",
    "# X = tfidf.fit_transform(split_data['text'])\n",
    "# X.shape # (1867535, 933053)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = pd.read_csv(path + 'emotion.csv')\n",
    "\n",
    "# set(emotions['emotion'])\n",
    "\n",
    "sadness = emotions.loc[emotions['emotion'] == 'sadness']\n",
    "disgust = emotions.loc[emotions['emotion'] == 'disgust']\n",
    "anticipation = emotions.loc[emotions['emotion'] == 'anticipation']\n",
    "joy = emotions.loc[emotions['emotion'] == 'joy']\n",
    "anger = emotions.loc[emotions['emotion'] == 'anger']\n",
    "fear = emotions.loc[emotions['emotion'] == 'fear']\n",
    "surprise = emotions.loc[emotions['emotion'] == 'surprise']\n",
    "trust = emotions.loc[emotions['emotion'] == 'trust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion = pd.DataFrame(\n",
    "    [\n",
    "        len(sadness), len(disgust), len(anticipation), len(joy), len(anger), len(fear), len(surprise), len(trust)\n",
    "    ],\n",
    "    [\n",
    "        'sadness', 'disgust', 'anticipation', 'joy', 'anger', 'fear', 'surprise', 'trust'\n",
    "    ]\n",
    "    , columns=['count'])\n",
    "display(df_emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace Bert testing.\n",
    "I use HuggingFace as support in this homework, and I follow this link.\n",
    "https://huggingface.co/docs/transformers/index\n",
    "\n",
    "this is HuggingFace's official tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, I use HuggingFace's \"bert-base-uncased\" pre-trained model.\n",
    "You can find all pre-trained model on this link.\n",
    "\n",
    "https://huggingface.co/models\n",
    "\n",
    "Notice that the official document tell us `from_pretrained()` method uses `torch.load()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indexes = tweet_train_predict_split.loc[tweet_train_predict_split['identification'] == 'train'].index\n",
    "predict_indexes = tweet_train_predict_split.loc[tweet_train_predict_split['identification'] == 'test'].index\n",
    "\n",
    "train_data_df = pd.DataFrame(split_data.iloc[train_indexes]['text'])\n",
    "predict_data_df = pd.DataFrame(split_data.iloc[predict_indexes]['text'])\n",
    "\n",
    "train_data_df.reset_index(drop=True, inplace=True)\n",
    "tweets_label.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_data_df = pd.concat([train_data_df, tweets_label], axis=1)\n",
    "train_data_df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this part, I want to split my dataset into `train dataset` and `validation dataset`, and I have some problem here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets_split(dataset, ratio):\n",
    "    length = len(dataset)\n",
    "    shuffle_index = np.random.permutation(length)\n",
    "    test_size = int(length * ratio)\n",
    "    train_data = dataset.iloc[shuffle_index[test_size:]]\n",
    "    test_data = dataset.iloc[shuffle_index[:test_size]]\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "X_train, X_test = datasets_split(train_data_df, 0.2)\n",
    "\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Although I only change column name `emotion` to `label`,\n",
    "# but it can't work with X_train.columns.values[1] = 'label',\n",
    "# and I can't find the reason\n",
    "X_train.columns = ['text', 'label']\n",
    "X_test.columns = ['text', 'label']\n",
    "\n",
    "# I want to store my training and test dataset into csv file, and read them use `load_dataset()` later,\n",
    "# it store successfully.\n",
    "X_train.to_csv('selfmade-datasets/train.csv', index=False, line_terminator='\\n')\n",
    "X_test.to_csv('selfmade-datasets/test.csv', index=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import Dataset\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "encoder.fit(np.array(X_train['label']).reshape(-1, 1))\n",
    "encoder.categories_\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\") # choose pre-trained model\n",
    "\n",
    "def tokenizer_method(datas):\n",
    "    output = tokenizer(datas[\"text\"], padding=\"max_length\", truncation=True)\n",
    "    output['label'] = encoder.transform(np.array(datas['label']).reshape(-1, 1)).toarray()\n",
    "    return output\n",
    "\n",
    "\n",
    "dataset = datasets.DatasetDict(\n",
    "    {\n",
    "        'train': Dataset.from_pandas(X_train),\n",
    "        'test': Dataset.from_pandas(X_test),\n",
    "    }\n",
    ")\n",
    "\n",
    "# print(dataset['train'])\n",
    "# print(dataset['train'][1])\n",
    "# print(dataset['train']['text'][:5])\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenizer_method, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_COUNT = len(encoder.categories_[0])\n",
    "# print(tokenized_dataset['train'][1]['token_type_ids'], end='\\n\\n')\n",
    "# print(tokenized_dataset['train'][1]['attention_mask'], end='\\n\\n')\n",
    "# print(tokenized_dataset['train'][1]['label'], end='\\n\\n')\n",
    "# print(tokenized_dataset['train'][1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=LABEL_COUNT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import evaluate\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"training_result\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=64,\n",
    "    num_train_epochs=1,\n",
    "    save_steps=100000,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OverLapping occur here, so I want to do underlapping and check the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data overlapping occured here, so I want to do\n",
    "min_emotion_cnt = int(df_emotion.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reuse `train_data_df` variable from upper cell\n",
    "\n",
    "sadness_sample = train_data_df.loc[train_data_df['emotion'] == 'sadness'].sample(n=min_emotion_cnt)\n",
    "disgust_sample = train_data_df.loc[train_data_df['emotion'] == 'disgust'].sample(n=min_emotion_cnt)\n",
    "anticipation_sample = train_data_df.loc[train_data_df['emotion'] == 'anticipation'].sample(n=min_emotion_cnt)\n",
    "joy_sample = train_data_df.loc[train_data_df['emotion'] == 'joy'].sample(n=min_emotion_cnt)\n",
    "anger_sample = train_data_df.loc[train_data_df['emotion'] == 'anger'].sample(n=min_emotion_cnt)\n",
    "fear_sample = train_data_df.loc[train_data_df['emotion'] == 'fear'].sample(n=min_emotion_cnt)\n",
    "surprise_sample = train_data_df.loc[train_data_df['emotion'] == 'surprise'].sample(n=min_emotion_cnt)\n",
    "trust_sample = train_data_df.loc[train_data_df['emotion'] == 'trust'].sample(n=min_emotion_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_train_data_df = pd.concat([\n",
    "    sadness_sample,\n",
    "    disgust_sample,\n",
    "    anticipation_sample,\n",
    "    joy_sample,\n",
    "    anger_sample,\n",
    "    fear_sample,\n",
    "    surprise_sample,\n",
    "    trust_sample\n",
    "]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "sampling_train_data_df = sampling_train_data_df.rename(columns={ 'emotion': 'label' })\n",
    "display(sampling_train_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_train_data_df.to_csv('undersampling_datasets.csv', index=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(np.array(sampling_train_data_df['label']).reshape(-1, 1))\n",
    "SAMPLE_LABEL_COUNT = len(encoder.categories_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\") # choose pre-trained model\n",
    "\n",
    "def tokenizer_method(datas):\n",
    "    output = tokenizer(datas[\"text\"], padding=\"max_length\", truncation=True)\n",
    "    output['label'] = encoder.transform(np.array(datas['label']).reshape(-1, 1)).toarray()\n",
    "    return output\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "sampling_dataset = datasets.DatasetDict(\n",
    "    {\n",
    "        'train': Dataset.from_pandas(sampling_train_data_df),\n",
    "    }\n",
    ")\n",
    "\n",
    "sampling_tokenized_dataset = sampling_dataset.map(tokenizer_method, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=SAMPLE_LABEL_COUNT)\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import evaluate\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "sampling_training_args = TrainingArguments(\n",
    "    output_dir=\"sampling_training_result\",\n",
    "    eval_accumulation_steps=\"epoch\",\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=1,\n",
    "    save_steps=100000,\n",
    ")\n",
    "\n",
    "sampling_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=sampling_training_args,\n",
    "    train_dataset=sampling_tokenized_dataset['train'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "torch.cuda.set_device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('hf-dm3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b4ad8ec340707d92b214921b5e58f09856aa67a231f9ea7cea62d323e3ffe821"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
